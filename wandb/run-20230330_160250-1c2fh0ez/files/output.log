========================================
Total Params: 71891291
Trainable Params: 71891291
Non-trainable Params: 0
========================================
LOG FORMAT | segmentation_LOSS mIoU pixAcc | depth_LOSS abs_err rel_err | normal_LOSS mean median <11.25 <22.5 <30 | TIME
Epoch 0/199
self_multiinpout False
753
tensor([3.0449, 0.7070, 1.0451], device='cuda:0', grad_fn=<CopySlices>)
{'segmentation': 3.044912099838257, 'depth': 0.70698082447052, 'normal': 1.0451011657714844}

  0%|▎                                                                                                                                  | 2/753 [00:03<19:44,  1.58s/it]
tensor([2.9071, 0.7235, 1.1450], device='cuda:0', grad_fn=<CopySlices>)

  0%|▌                                                                                                                                  | 3/753 [00:04<19:26,  1.56s/it]
tensor([2.6504, 0.8828, 1.1662], device='cuda:0', grad_fn=<CopySlices>)

  1%|▋                                                                                                                                  | 4/753 [00:06<19:18,  1.55s/it]
tensor([2.6796, 1.0207, 0.9607], device='cuda:0', grad_fn=<CopySlices>)
  1%|▋                                                                                                                                  | 4/753 [00:07<24:12,  1.94s/it]
Traceback (most recent call last):
  File "examples/warehouseSIM/train_warehouseSIM.py", line 126, in <module>
    main(params)
  File "examples/warehouseSIM/train_warehouseSIM.py", line 118, in main
    NYUmodel.train(nyuv2_train_loader, nyuv2_test_loader, 200)
  File "/home/dim/mdpi_robotics/LibMTL/LibMTL/trainer.py", line 230, in train
    self.optimizer.step()
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/optimizer.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/adam.py", line 108, in step
    F.adam(params_with_grad,
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/_functional.py", line 85, in adam
    exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)
KeyboardInterrupt