========================================
Total Params: 71891291
Trainable Params: 71891291
Non-trainable Params: 0
========================================
LOG FORMAT | segmentation_LOSS mIoU pixAcc | depth_LOSS abs_err rel_err | normal_LOSS mean median <11.25 <22.5 <30 | TIME
Epoch 0/199
self_multiinpout False
  0%|                                                       | 0/753 [00:00<?, ?it/s]
tensor([3.0449, 0.7070, 1.0451], device='cuda:0', grad_fn=<CopySlices>)

  0%|                                               | 2/753 [00:03<21:38,  1.73s/it]

  0%|â–                                              | 3/753 [00:05<24:22,  1.95s/it]
Traceback (most recent call last):
  File "examples/warehouseSIM/train_warehouseSIM.py", line 126, in <module>
    main(params)
  File "examples/warehouseSIM/train_warehouseSIM.py", line 118, in main
    NYUmodel.train(nyuv2_train_loader, nyuv2_test_loader, 200)
  File "/home/dim/mdpi_robotics/LibMTL/LibMTL/trainer.py", line 229, in train
    self.optimizer.step()
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/optimizer.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/adam.py", line 108, in step
    F.adam(params_with_grad,
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/_functional.py", line 85, in adam
    exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)
KeyboardInterrupt