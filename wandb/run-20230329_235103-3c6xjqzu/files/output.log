========================================
Total Params: 71888721
Trainable Params: 71888721
Non-trainable Params: 0
========================================
LOG FORMAT | segmentation_LOSS mIoU pixAcc | depth_LOSS abs_err rel_err | normal_LOSS mean median <11.25 <22.5 <30 | TIME
/zhome/e0/1/158047/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
loss: 6.330452919006348, losses: tensor([2.6375, 2.3860, 1.3069], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 5.6625189781188965, losses: tensor([2.5186, 2.2748, 0.8691], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 5.599362850189209, losses: tensor([2.5315, 2.3893, 0.6785], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 5.562108993530273, losses: tensor([2.3911, 2.5186, 0.6525], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 5.215183258056641, losses: tensor([2.3580, 2.2798, 0.5773], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 5.192415237426758, losses: tensor([2.4171, 2.1758, 0.5995], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 5.0958251953125, losses: tensor([2.2782, 2.2924, 0.5252], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.83357572555542, losses: tensor([2.3191, 2.0901, 0.4244], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.486878871917725, losses: tensor([2.2351, 1.8029, 0.4488], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.4177141189575195, losses: tensor([2.1704, 1.8864, 0.3609], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.804686069488525, losses: tensor([2.2978, 1.9648, 0.5420], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.815515518188477, losses: tensor([2.1201, 2.2700, 0.4254], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.4869704246521, losses: tensor([2.3166, 1.7189, 0.4515], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 5.055838584899902, losses: tensor([2.1820, 2.4181, 0.4557], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.38333797454834, losses: tensor([2.3301, 1.5758, 0.4775], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.326944828033447, losses: tensor([2.1824, 1.7306, 0.4139], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.9140195846557617, losses: tensor([2.3435, 1.1776, 0.3928], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.344720840454102, losses: tensor([2.1455, 1.8054, 0.3938], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.292303085327148, losses: tensor([2.2730, 1.5930, 0.4262], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.9602017402648926, losses: tensor([2.2398, 1.3273, 0.3931], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.650322198867798, losses: tensor([2.0685, 1.2013, 0.3805], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.238116264343262, losses: tensor([2.2457, 1.6319, 0.3605], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.208066940307617, losses: tensor([2.2154, 1.5565, 0.4362], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.067141532897949, losses: tensor([1.9935, 1.6659, 0.4077], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.016153812408447, losses: tensor([2.3176, 1.2467, 0.4518], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.580650329589844, losses: tensor([2.0743, 2.1220, 0.3844], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.087225437164307, losses: tensor([1.9645, 1.8092, 0.3135], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.7305989265441895, losses: tensor([2.1466, 1.1933, 0.3907], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.045316219329834, losses: tensor([2.2169, 1.4451, 0.3833], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2161834239959717, losses: tensor([1.9332, 0.9514, 0.3316], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 4.116608619689941, losses: tensor([2.2851, 1.4480, 0.3835], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.5773253440856934, losses: tensor([2.1149, 1.1288, 0.3336], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.3358163833618164, losses: tensor([1.9542, 1.0719, 0.3097], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.5556023120880127, losses: tensor([2.2487, 0.9743, 0.3326], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.496448516845703, losses: tensor([2.2076, 0.9857, 0.3032], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.683786392211914, losses: tensor([2.0219, 1.3171, 0.3448], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.7482447624206543, losses: tensor([2.2480, 1.1626, 0.3376], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.5808465480804443, losses: tensor([1.8155, 1.4316, 0.3338], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.684936285018921, losses: tensor([2.1545, 1.2075, 0.3229], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.42032527923584, losses: tensor([1.8519, 1.2002, 0.3682], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.690464973449707, losses: tensor([2.2340, 1.1010, 0.3555], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2260375022888184, losses: tensor([1.9354, 0.9547, 0.3360], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2208642959594727, losses: tensor([1.9805, 0.8777, 0.3626], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2291252613067627, losses: tensor([2.0728, 0.8387, 0.3176], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.539090633392334, losses: tensor([2.2247, 0.9778, 0.3365], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.1167819499969482, losses: tensor([2.0395, 0.7517, 0.3256], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.3497607707977295, losses: tensor([2.1488, 0.8373, 0.3637], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.3202414512634277, losses: tensor([1.8997, 1.1220, 0.2986], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.1373486518859863, losses: tensor([1.9586, 0.8522, 0.3265], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.266735553741455, losses: tensor([2.0002, 0.9513, 0.3152], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2085530757904053, losses: tensor([1.7952, 1.1070, 0.3063], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.6316933631896973, losses: tensor([1.9339, 1.3474, 0.3504], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2814738750457764, losses: tensor([1.9594, 0.9687, 0.3533], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.357191801071167, losses: tensor([1.9041, 1.1553, 0.2978], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.1598687171936035, losses: tensor([1.6980, 1.1825, 0.2794], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.924870491027832, losses: tensor([1.9653, 0.6885, 0.2710], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8667140007019043, losses: tensor([1.9515, 0.5921, 0.3231], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2057154178619385, losses: tensor([1.9342, 0.9425, 0.3291], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.4426050186157227, losses: tensor([1.9430, 1.1376, 0.3621], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.565952777862549, losses: tensor([2.2459, 0.9510, 0.3691], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.0422863960266113, losses: tensor([1.9132, 0.8086, 0.3205], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.5915727615356445, losses: tensor([1.8594, 1.4156, 0.3166], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.482710599899292, losses: tensor([2.1904, 0.9465, 0.3458], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.0524630546569824, losses: tensor([1.7400, 0.9940, 0.3185], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.9267287254333496, losses: tensor([1.6914, 0.9390, 0.2963], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2415990829467773, losses: tensor([1.8311, 1.0780, 0.3325], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2838075160980225, losses: tensor([1.9991, 0.9862, 0.2986], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.036876916885376, losses: tensor([1.7675, 0.9438, 0.3256], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.15169358253479, losses: tensor([1.8978, 0.9115, 0.3425], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.6212923526763916, losses: tensor([2.0203, 1.2595, 0.3416], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.545747995376587, losses: tensor([1.7800, 0.4947, 0.2710], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.021350860595703, losses: tensor([1.8728, 0.8093, 0.3393], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.965965747833252, losses: tensor([1.9024, 0.7701, 0.2935], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8093416690826416, losses: tensor([1.6296, 0.8548, 0.3250], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.573392629623413, losses: tensor([2.1593, 1.0735, 0.3406], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.916780710220337, losses: tensor([1.7950, 0.8088, 0.3130], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2448105812072754, losses: tensor([1.8568, 1.1112, 0.2768], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.900329351425171, losses: tensor([1.7855, 0.8172, 0.2976], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.9555788040161133, losses: tensor([1.8036, 0.8620, 0.2900], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.484232187271118, losses: tensor([1.8926, 1.2511, 0.3404], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.6805002689361572, losses: tensor([1.7205, 0.6525, 0.3075], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.1028666496276855, losses: tensor([1.7053, 1.0978, 0.2997], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.936391830444336, losses: tensor([1.7835, 0.8482, 0.3047], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.229501247406006, losses: tensor([1.8981, 1.0163, 0.3151], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.4284181594848633, losses: tensor([1.8793, 1.2736, 0.2755], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.361077308654785, losses: tensor([2.0606, 0.9473, 0.3532], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.084716796875, losses: tensor([1.8617, 0.9081, 0.3150], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.0028235912323, losses: tensor([1.8100, 0.9087, 0.2842], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.6642215251922607, losses: tensor([1.7964, 0.5857, 0.2820], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.0136313438415527, losses: tensor([1.8779, 0.8560, 0.2797], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.7813873291015625, losses: tensor([1.7294, 0.6744, 0.3776], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.270326852798462, losses: tensor([1.7552, 1.2064, 0.3087], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.1134486198425293, losses: tensor([1.7899, 1.0215, 0.3020], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.3552699089050293, losses: tensor([1.9588, 1.0787, 0.3178], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.816592216491699, losses: tensor([1.6155, 0.9026, 0.2985], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.973318576812744, losses: tensor([1.6599, 1.0166, 0.2968], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8903021812438965, losses: tensor([1.8563, 0.7344, 0.2996], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8670153617858887, losses: tensor([1.7733, 0.7488, 0.3449], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.1923811435699463, losses: tensor([2.0402, 0.8274, 0.3248], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
Epoch: 0000 | TRAIN: 2.0217 0.0831 0.3539 | 1.2344 1.2311 0.4845 | 0.3719 46.9765 43.8722 0.0443 0.1689 0.2786 | Time: 126.5679 | TEST: 1.9138 0.1028 0.3893 | 1.6561 1.6433 0.5793 | 0.3108 42.3665 40.5611 0.0561 0.2054 0.3263 | Time: 19.4185
loss: 2.8420469760894775, losses: tensor([1.7836, 0.7625, 0.2960], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')893 | 1.6561 1.6433 0.5793 | 0.3108 42.3665 40.5611 0.0561 0.2054 0.3263 | Time: 19.4185
loss: 3.2588095664978027, losses: tensor([1.7365, 1.1955, 0.3269], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.769582748413086, losses: tensor([1.6257, 0.8526, 0.2913], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.033649444580078, losses: tensor([1.9087, 0.8185, 0.3065], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.64473557472229, losses: tensor([1.7034, 0.6726, 0.2688], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.9637064933776855, losses: tensor([1.7765, 0.8626, 0.3246], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8420469760894775, losses: tensor([1.7836, 0.7625, 0.2960], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')893 | 1.6561 1.6433 0.5793 | 0.3108 42.3665 40.5611 0.0561 0.2054 0.3263 | Time: 19.4185
loss: 2.9099159240722656, losses: tensor([1.7137, 0.9282, 0.2681], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.096409320831299, losses: tensor([1.6920, 1.1240, 0.2804], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.586505889892578, losses: tensor([1.6837, 0.6466, 0.2563], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.136242389678955, losses: tensor([1.7707, 1.0418, 0.3237], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2738404273986816, losses: tensor([1.8095, 1.1912, 0.2732], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.301525115966797, losses: tensor([2.0694, 0.8870, 0.3451], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8822362422943115, losses: tensor([1.6481, 0.9166, 0.3175], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.96722412109375, losses: tensor([1.8283, 0.8573, 0.2816], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8644161224365234, losses: tensor([1.7919, 0.7857, 0.2868], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.0624327659606934, losses: tensor([2.0233, 0.7182, 0.3209], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.0982437133789062, losses: tensor([1.6888, 1.0691, 0.3404], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.6836798191070557, losses: tensor([1.7397, 0.6754, 0.2686], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.054131507873535, losses: tensor([1.7840, 0.9368, 0.3334], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.865917444229126, losses: tensor([1.8775, 0.6841, 0.3043], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.5461041927337646, losses: tensor([1.5912, 0.6564, 0.2985], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.915131092071533, losses: tensor([1.8042, 0.8030, 0.3079], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8366782665252686, losses: tensor([1.7172, 0.7910, 0.3284], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.1073410511016846, losses: tensor([1.8666, 0.8597, 0.3811], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.255460262298584, losses: tensor([1.9636, 0.9873, 0.3045], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.7985150814056396, losses: tensor([1.7235, 0.8025, 0.2725], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.653743028640747, losses: tensor([1.6123, 0.7284, 0.3130], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.7704992294311523, losses: tensor([1.6641, 0.7645, 0.3419], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.192366123199463, losses: tensor([1.7378, 1.1224, 0.3322], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.6140947341918945, losses: tensor([1.7128, 0.5944, 0.3070], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2344586849212646, losses: tensor([1.7784, 1.1438, 0.3123], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.6639537811279297, losses: tensor([1.6961, 0.6567, 0.3111], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.6338388919830322, losses: tensor([1.6541, 0.6960, 0.2837], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.9276962280273438, losses: tensor([1.8853, 0.7169, 0.3254], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8373804092407227, losses: tensor([1.5534, 1.0158, 0.2682], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.109180450439453, losses: tensor([1.9274, 0.8517, 0.3300], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.4525017738342285, losses: tensor([2.0319, 1.0885, 0.3321], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.7952239513397217, losses: tensor([1.6813, 0.8077, 0.3061], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8504691123962402, losses: tensor([1.9245, 0.6023, 0.3237], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8831729888916016, losses: tensor([1.6040, 0.9363, 0.3429], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.9183433055877686, losses: tensor([1.8270, 0.7508, 0.3406], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.433471202850342, losses: tensor([1.7754, 1.3836, 0.2744], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.706972360610962, losses: tensor([1.7294, 0.7113, 0.2663], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.749779224395752, losses: tensor([1.7463, 0.7047, 0.2987], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.995041847229004, losses: tensor([1.6244, 1.0368, 0.3338], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8854570388793945, losses: tensor([1.7356, 0.8648, 0.2851], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.003678560256958, losses: tensor([1.7901, 0.9144, 0.2992], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.9379875659942627, losses: tensor([1.7657, 0.8334, 0.3389], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.975762128829956, losses: tensor([1.9130, 0.7539, 0.3088], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.6584815979003906, losses: tensor([1.5955, 0.8022, 0.2609], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.690610408782959, losses: tensor([1.7220, 0.6767, 0.2919], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.498944044113159, losses: tensor([1.5519, 0.6273, 0.3198], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.820880889892578, losses: tensor([1.6935, 0.8298, 0.2976], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.832758903503418, losses: tensor([1.6891, 0.8724, 0.2713], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.627500534057617, losses: tensor([1.5243, 0.7742, 0.3290], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.795693874359131, losses: tensor([1.6656, 0.8552, 0.2749], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8863284587860107, losses: tensor([1.6938, 0.8920, 0.3005], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.4371705055236816, losses: tensor([1.6033, 0.5745, 0.2593], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.6207118034362793, losses: tensor([1.7815, 0.5326, 0.3066], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.6711156368255615, losses: tensor([1.6697, 0.6874, 0.3140], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.41955828666687, losses: tensor([1.9535, 1.1654, 0.3006], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.6810996532440186, losses: tensor([1.8413, 0.5649, 0.2749], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.045574188232422, losses: tensor([1.6095, 1.1256, 0.3105], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.669182777404785, losses: tensor([1.6812, 0.6799, 0.3081], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.114227771759033, losses: tensor([1.8923, 0.8990, 0.3230], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.0080909729003906, losses: tensor([1.8403, 0.8660, 0.3018], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8061563968658447, losses: tensor([1.8117, 0.6806, 0.3138], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.4586868286132812, losses: tensor([1.4565, 0.7144, 0.2878], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.7375988960266113, losses: tensor([1.6639, 0.7496, 0.3241], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.1206626892089844, losses: tensor([1.8478, 0.9395, 0.3334], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.9537317752838135, losses: tensor([1.9375, 0.7363, 0.2799], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.7120180130004883, losses: tensor([1.6574, 0.7738, 0.2809], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.5313515663146973, losses: tensor([1.5441, 0.6793, 0.3079], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.785665988922119, losses: tensor([1.5590, 0.8855, 0.3411], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.586439371109009, losses: tensor([1.7674, 0.5379, 0.2812], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.229989528656006, losses: tensor([1.8403, 1.0331, 0.3566], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.326023817062378, losses: tensor([2.1961, 0.8179, 0.3121], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.873528242111206, losses: tensor([1.7481, 0.8221, 0.3033], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.8232274055480957, losses: tensor([1.7345, 0.7789, 0.3098], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.1138358116149902, losses: tensor([1.7801, 1.0210, 0.3127], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.4761111736297607, losses: tensor([1.3090, 0.8899, 0.2772], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.846522092819214, losses: tensor([1.8234, 0.7144, 0.3087], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.906562566757202, losses: tensor([1.7945, 0.8467, 0.2653], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.2948710918426514, losses: tensor([1.9304, 1.0145, 0.3500], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.860285758972168, losses: tensor([1.7901, 0.7403, 0.3299], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.5819783210754395, losses: tensor([1.6801, 0.6028, 0.2991], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.5414438247680664, losses: tensor([1.6441, 0.6373, 0.2600], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.6152706146240234, losses: tensor([1.6526, 0.6206, 0.3420], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 3.1660943031311035, losses: tensor([1.6645, 1.1765, 0.3251], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.7797210216522217, losses: tensor([1.8223, 0.6417, 0.3157], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.5317344665527344, losses: tensor([1.6163, 0.6449, 0.2705], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.810645580291748, losses: tensor([1.6761, 0.8043, 0.3303], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.754244804382324, losses: tensor([1.8596, 0.5893, 0.3053], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
Epoch: 0001 | TRAIN: 1.7492 0.0995 0.4144 | 0.8324 0.8301 0.3717 | 0.3065 42.2776 40.9619 0.0556 0.1978 0.3163 | Time: 126.6199 | TEST: 1.7696 0.1099 0.4078 | 1.0066 0.9978 0.3394 | 0.3019 41.7287 40.4830 0.0630 0.2121 0.3281 | Time: 19.3824
loss: 2.730739116668701, losses: tensor([1.7300, 0.6992, 0.3016], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')4078 | 1.0066 0.9978 0.3394 | 0.3019 41.7287 40.4830 0.0630 0.2121 0.3281 | Time: 19.3824
loss: 2.9798402786254883, losses: tensor([1.8016, 0.8676, 0.3106], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.93770170211792, losses: tensor([1.9372, 0.6823, 0.3182], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.82231068611145, losses: tensor([1.7156, 0.8227, 0.2840], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.786388397216797, losses: tensor([1.7421, 0.8043, 0.2400], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
loss: 2.738011121749878, losses: tensor([1.6186, 0.7829, 0.3365], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')
Epoch: 0002 | TRAIN: 1.6822 0.1109 0.4224 | 0.7858 0.7832 0.3640 | 0.3017 41.6536 40.2021 0.0650 0.2197 0.3372 | Time: 126.6588 |
loss: 2.730739116668701, losses: tensor([1.7300, 0.6992, 0.3016], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')4078 | 1.0066 0.9978 0.3394 | 0.3019 41.7287 40.4830 0.0630 0.2121 0.3281 | Time: 19.3824
Epoch: 0003 | TRAIN: 1.6357 0.1228 0.4389 | 0.7429 0.7402 0.3554 | 0.2910 40.7483 39.1173 0.0690 0.2301 0.3513 | Time: 126.4092 | , 1.], device='cuda:0')078 | 1.0066 0.9978 0.3394 | 0.3019 41.7287 40.4830 0.0630 0.2121 0.3281 | Time: 19.3824
Epoch: 0003 | TRAIN: 1.6357 0.1228 0.4389 | 0.7429 0.7402 0.3554 | 0.2910 40.7483 39.1173 0.0690 0.2301 0.3513 | Time: 126.4092 | TEST: 1.7452 0.1251 0.4049 | 0.9633 0.9540 0.3927 | 0.2923 40.3038 38.2887 0.0895 0.2542 0.3711 | Time: 19.3729
loss: 2.7949655055999756, losses: tensor([1.6271, 0.8994, 0.2684], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')049 | 0.9633 0.9540 0.3927 | 0.2923 40.3038 38.2887 0.0895 0.2542 0.3711 | Time: 19.3729

loss: 3.3530139923095703, losses: tensor([1.8007, 1.2255, 0.3268], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')049 | 0.9633 0.9540 0.3927 | 0.2923 40.3038 38.2887 0.0895 0.2542 0.3711 | Time: 19.3729
Epoch: 0005 | TRAIN: 1.5564 0.1600 0.4680 | 0.7127 0.7104 0.3440 | 0.2757 39.2412 37.2469 0.0840 0.2587 0.3833 | Time: 126.4735 |  1.], device='cuda:0'))049 | 0.9633 0.9540 0.3927 | 0.2923 40.3038 38.2887 0.0895 0.2542 0.3711 | Time: 19.3729
Epoch: 0005 | TRAIN: 1.5564 0.1600 0.4680 | 0.7127 0.7104 0.3440 | 0.2757 39.2412 37.2469 0.0840 0.2587 0.3833 | Time: 126.4735 | TEST: 1.5633 0.1522 0.4607 | 0.7724 0.7661 0.3281 | 0.2668 37.9151 35.8851 0.1190 0.2965 0.4119 | Time: 19.4261
Epoch: 0006 | TRAIN: 1.5171 0.1657 0.4768 | 0.6949 0.6928 0.3315 | 0.2716 38.7893 36.5271 0.0895 0.2682 0.3936 | Time: 126.7393 | , 1.], device='cuda:0')607 | 0.7724 0.7661 0.3281 | 0.2668 37.9151 35.8851 0.1190 0.2965 0.4119 | Time: 19.4261
Epoch: 0006 | TRAIN: 1.5171 0.1657 0.4768 | 0.6949 0.6928 0.3315 | 0.2716 38.7893 36.5271 0.0895 0.2682 0.3936 | Time: 126.7393 | TEST: 1.5519 0.1722 0.4659 | 0.8003 0.7916 0.2868 | 0.2598 37.8393 35.8832 0.0921 0.2769 0.4035 | Time: 19.4236
Epoch: 0007 | TRAIN: 1.4733 0.1831 0.4923 | 0.7045 0.7026 0.3296 | 0.2633 38.0316 35.7162 0.0979 0.2801 0.4066 | Time: 126.4668 |  1.], device='cuda:0')4659 | 0.8003 0.7916 0.2868 | 0.2598 37.8393 35.8832 0.0921 0.2769 0.4035 | Time: 19.4236
Epoch: 0007 | TRAIN: 1.4733 0.1831 0.4923 | 0.7045 0.7026 0.3296 | 0.2633 38.0316 35.7162 0.0979 0.2801 0.4066 | Time: 126.4668 | TEST: 1.5508 0.1731 0.4743 | 0.8351 0.8267 0.3329 | 0.2587 37.3603 35.0025 0.1119 0.2957 0.4197 | Time: 19.3969
Epoch: 0008 | TRAIN: 1.4286 0.2071 0.5056 | 0.6625 0.6594 0.3133 | 0.2569 37.3404 34.7052 0.1054 0.2961 0.4233 | Time: 126.7193 | , 1.], device='cuda:0')743 | 0.8351 0.8267 0.3329 | 0.2587 37.3603 35.0025 0.1119 0.2957 0.4197 | Time: 19.3969
Epoch: 0008 | TRAIN: 1.4286 0.2071 0.5056 | 0.6625 0.6594 0.3133 | 0.2569 37.3404 34.7052 0.1054 0.2961 0.4233 | Time: 126.7193 | TEST: 1.5714 0.1759 0.4569 | 0.7476 0.7418 0.3036 | 0.2568 37.1859 34.7739 0.1139 0.3022 0.4249 | Time: 19.3857
Epoch: 0009 | TRAIN: 1.4228 0.2069 0.5087 | 0.6652 0.6645 0.3206 | 0.2507 36.7571 34.0857 0.1133 0.3045 0.4330 | Time: 126.6486 | , 1.], device='cuda:0')569 | 0.7476 0.7418 0.3036 | 0.2568 37.1859 34.7739 0.1139 0.3022 0.4249 | Time: 19.3857
Epoch: 0009 | TRAIN: 1.4228 0.2069 0.5087 | 0.6652 0.6645 0.3206 | 0.2507 36.7571 34.0857 0.1133 0.3045 0.4330 | Time: 126.6486 | TEST: 1.5243 0.1927 0.4767 | 0.8269 0.8178 0.2928 | 0.2496 36.6968 34.3363 0.1108 0.3000 0.4282 | Time: 19.4132
Epoch: 0010 | TRAIN: 1.3921 0.2213 0.5215 | 0.6401 0.6385 0.3023 | 0.2490 36.4816 33.6592 0.1201 0.3134 0.4410 | Time: 126.6725 |  1.], device='cuda:0')4767 | 0.8269 0.8178 0.2928 | 0.2496 36.6968 34.3363 0.1108 0.3000 0.4282 | Time: 19.4132
Epoch: 0010 | TRAIN: 1.3921 0.2213 0.5215 | 0.6401 0.6385 0.3023 | 0.2490 36.4816 33.6592 0.1201 0.3134 0.4410 | Time: 126.6725 | TEST: 1.4307 0.2149 0.5023 | 0.7427 0.7358 0.2712 | 0.2417 35.6258 32.8743 0.1378 0.3326 0.4551 | Time: 19.4928
Epoch: 0011 | TRAIN: 1.3581 0.2442 0.5285 | 0.6342 0.6335 0.3020 | 0.2483 36.4336 33.6542 0.1200 0.3132 0.4407 | Time: 126.5870 |  1.], device='cuda:0')5023 | 0.7427 0.7358 0.2712 | 0.2417 35.6258 32.8743 0.1378 0.3326 0.4551 | Time: 19.4928
Epoch: 0011 | TRAIN: 1.3581 0.2442 0.5285 | 0.6342 0.6335 0.3020 | 0.2483 36.4336 33.6542 0.1200 0.3132 0.4407 | Time: 126.5870 | TEST: 1.4366 0.2274 0.5101 | 0.8533 0.8443 0.3034 | 0.2368 35.4405 33.1832 0.1309 0.3216 0.4475 | Time: 19.3591
Epoch: 0012 | TRAIN: 1.2972 0.2632 0.5471 | 0.6221 0.6213 0.2997 | 0.2398 35.6370 32.6774 0.1277 0.3258 0.4556 | Time: 126.7094 | , 1.], device='cuda:0')101 | 0.8533 0.8443 0.3034 | 0.2368 35.4405 33.1832 0.1309 0.3216 0.4475 | Time: 19.3591
Epoch: 0012 | TRAIN: 1.2972 0.2632 0.5471 | 0.6221 0.6213 0.2997 | 0.2398 35.6370 32.6774 0.1277 0.3258 0.4556 | Time: 126.7094 | TEST: 1.4823 0.2246 0.4970 | 0.7509 0.7438 0.2806 | 0.2393 35.5330 32.8086 0.1328 0.3284 0.4549 | Time: 19.4606
Epoch: 0013 | TRAIN: 1.2710 0.2740 0.5602 | 0.5979 0.5959 0.2799 | 0.2382 35.4265 32.4593 0.1334 0.3312 0.4597 | Time: 126.4841 | , 1.], device='cuda:0')970 | 0.7509 0.7438 0.2806 | 0.2393 35.5330 32.8086 0.1328 0.3284 0.4549 | Time: 19.4606
Epoch: 0013 | TRAIN: 1.2710 0.2740 0.5602 | 0.5979 0.5959 0.2799 | 0.2382 35.4265 32.4593 0.1334 0.3312 0.4597 | Time: 126.4841 | TEST: 1.4514 0.2250 0.5119 | 0.7655 0.7599 0.3540 | 0.2344 34.8993 32.1295 0.1491 0.3433 0.4662 | Time: 19.4014
Epoch: 0014 | TRAIN: 1.2613 0.2885 0.5635 | 0.6053 0.6037 0.2835 | 0.2349 35.0717 31.9944 0.1383 0.3391 0.4673 | Time: 126.7632 | , 1.], device='cuda:0')119 | 0.7655 0.7599 0.3540 | 0.2344 34.8993 32.1295 0.1491 0.3433 0.4662 | Time: 19.4014
Epoch: 0014 | TRAIN: 1.2613 0.2885 0.5635 | 0.6053 0.6037 0.2835 | 0.2349 35.0717 31.9944 0.1383 0.3391 0.4673 | Time: 126.7632 | TEST: 1.4429 0.2213 0.5058 | 0.7189 0.7114 0.2656 | 0.2305 34.3021 31.1198 0.1646 0.3614 0.4827 | Time: 19.3994
Epoch: 0015 | TRAIN: 1.2558 0.2905 0.5644 | 0.6047 0.6034 0.2857 | 0.2348 35.0999 31.9806 0.1343 0.3372 0.4671 | Time: 126.5622 | , 1.], device='cuda:0')058 | 0.7189 0.7114 0.2656 | 0.2305 34.3021 31.1198 0.1646 0.3614 0.4827 | Time: 19.3994
Epoch: 0015 | TRAIN: 1.2558 0.2905 0.5644 | 0.6047 0.6034 0.2857 | 0.2348 35.0999 31.9806 0.1343 0.3372 0.4671 | Time: 126.5622 | TEST: 1.3668 0.2568 0.5305 | 0.6853 0.6790 0.2585 | 0.2271 34.3729 31.5242 0.1459 0.3470 0.4752 | Time: 19.3924
Epoch: 0016 | TRAIN: 1.2371 0.2941 0.5732 | 0.5915 0.5898 0.2828 | 0.2313 34.6723 31.5051 0.1448 0.3466 0.4754 | Time: 126.8327 | , 1.], device='cuda:0')305 | 0.6853 0.6790 0.2585 | 0.2271 34.3729 31.5242 0.1459 0.3470 0.4752 | Time: 19.3924
Epoch: 0016 | TRAIN: 1.2371 0.2941 0.5732 | 0.5915 0.5898 0.2828 | 0.2313 34.6723 31.5051 0.1448 0.3466 0.4754 | Time: 126.8327 | TEST: 1.3417 0.2630 0.5393 | 0.6636 0.6568 0.2481 | 0.2203 33.5522 30.3874 0.1614 0.3674 0.4938 | Time: 19.6574
Epoch: 0017 | TRAIN: 1.2028 0.3078 0.5815 | 0.5940 0.5920 0.2858 | 0.2283 34.3334 30.9365 0.1484 0.3552 0.4846 | Time: 126.6492 | , 1.], device='cuda:0')393 | 0.6636 0.6568 0.2481 | 0.2203 33.5522 30.3874 0.1614 0.3674 0.4938 | Time: 19.6574
Epoch: 0017 | TRAIN: 1.2028 0.3078 0.5815 | 0.5940 0.5920 0.2858 | 0.2283 34.3334 30.9365 0.1484 0.3552 0.4846 | Time: 126.6492 | TEST: 1.2919 0.2765 0.5511 | 0.7247 0.7195 0.3231 | 0.2172 33.1681 29.9826 0.1721 0.3758 0.5003 | Time: 19.4505
Epoch: 0018 | TRAIN: 1.1686 0.3297 0.5964 | 0.5560 0.5546 0.2687 | 0.2241 33.9508 30.5798 0.1521 0.3602 0.4904 | Time: 126.6737 |  1.], device='cuda:0')5511 | 0.7247 0.7195 0.3231 | 0.2172 33.1681 29.9826 0.1721 0.3758 0.5003 | Time: 19.4505
Epoch: 0018 | TRAIN: 1.1686 0.3297 0.5964 | 0.5560 0.5546 0.2687 | 0.2241 33.9508 30.5798 0.1521 0.3602 0.4904 | Time: 126.6737 | TEST: 1.4147 0.2602 0.5019 | 0.6980 0.6910 0.2565 | 0.2173 33.3916 30.6277 0.1622 0.3631 0.4898 | Time: 19.3932
Epoch: 0019 | TRAIN: 1.1461 0.3401 0.6014 | 0.5628 0.5607 0.2660 | 0.2230 33.7444 30.2025 0.1583 0.3676 0.4967 | Time: 126.6482 | , 1.], device='cuda:0')019 | 0.6980 0.6910 0.2565 | 0.2173 33.3916 30.6277 0.1622 0.3631 0.4898 | Time: 19.3932
Epoch: 0019 | TRAIN: 1.1461 0.3401 0.6014 | 0.5628 0.5607 0.2660 | 0.2230 33.7444 30.2025 0.1583 0.3676 0.4967 | Time: 126.6482 | TEST: 1.3167 0.2771 0.5485 | 0.6448 0.6389 0.2567 | 0.2156 33.2150 30.2727 0.1631 0.3675 0.4955 | Time: 19.4448
Epoch: 0020 | TRAIN: 1.1308 0.3408 0.6058 | 0.5495 0.5489 0.2624 | 0.2224 33.6991 30.0325 0.1575 0.3699 0.4995 | Time: 126.5848 | , 1.], device='cuda:0')485 | 0.6448 0.6389 0.2567 | 0.2156 33.2150 30.2727 0.1631 0.3675 0.4955 | Time: 19.4448
Epoch: 0020 | TRAIN: 1.1308 0.3408 0.6058 | 0.5495 0.5489 0.2624 | 0.2224 33.6991 30.0325 0.1575 0.3699 0.4995 | Time: 126.5848 | TEST: 1.3003 0.2906 0.5514 | 0.6561 0.6509 0.2567 | 0.2145 32.9547 29.6953 0.1710 0.3780 0.5050 | Time: 19.4876
Epoch: 0021 | TRAIN: 1.0826 0.3562 0.6259 | 0.5433 0.5411 0.2599 | 0.2155 32.9703 29.2336 0.1697 0.3843 0.5125 | Time: 126.5836 | , 1.], device='cuda:0')514 | 0.6561 0.6509 0.2567 | 0.2145 32.9547 29.6953 0.1710 0.3780 0.5050 | Time: 19.4876
Epoch: 0021 | TRAIN: 1.0826 0.3562 0.6259 | 0.5433 0.5411 0.2599 | 0.2155 32.9703 29.2336 0.1697 0.3843 0.5125 | Time: 126.5836 | TEST: 1.3971 0.2593 0.5271 | 0.6643 0.6577 0.2568 | 0.2204 33.4341 30.1335 0.1685 0.3732 0.4979 | Time: 19.4773
loss: 1.8414716720581055, losses: tensor([1.0771, 0.5424, 0.2220], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')271 | 0.6643 0.6577 0.2568 | 0.2204 33.4341 30.1335 0.1685 0.3732 0.4979 | Time: 19.4773
loss: 1.8414716720581055, losses: tensor([1.0771, 0.5424, 0.2220], device='cuda:0', grad_fn=<CopySlices>), weights: tensor([1., 1., 1.], device='cuda:0')271 | 0.6643 0.6577 0.2568 | 0.2204 33.4341 30.1335 0.1685 0.3732 0.4979 | Time: 19.4773