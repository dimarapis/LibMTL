========================================
Total Params: 71891291
Trainable Params: 71891291
Non-trainable Params: 0
========================================
LOG FORMAT | segmentation_LOSS mIoU pixAcc | depth_LOSS abs_err rel_err | normal_LOSS mean median <11.25 <22.5 <30 | TIME
Epoch 0/199
self_multiinpout False
753
batch took 0.43348169326782227 seconds
batch took 0.38448238372802734 seconds
batch took 0.374647855758667 seconds
  0%|▊                                                                                                                                                                                               | 3/753 [00:01<04:53,  2.56it/s]
batch took 0.37270426750183105 seconds
batch took 0.3712480068206787 seconds
batch took 0.37479186058044434 seconds
batch took 0.36970973014831543 seconds
batch took 0.37421178817749023 seconds
batch took 0.3690989017486572 seconds

  1%|██▎                                                                                                                                                                                             | 9/753 [00:03<04:37,  2.68it/s]
  1%|██▊                                                                                                                                                                                            | 11/753 [00:04<05:06,  2.42it/s]
Traceback (most recent call last):
  File "examples/warehouseSIM/train_warehouseSIM.py", line 126, in <module>
    main(params)
  File "examples/warehouseSIM/train_warehouseSIM.py", line 118, in main
    NYUmodel.train(nyuv2_train_loader, nyuv2_test_loader, 200)
  File "/home/dim/mdpi_robotics/LibMTL/LibMTL/trainer.py", line 235, in train
    self.optimizer.step()
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/optimizer.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/adam.py", line 108, in step
    F.adam(params_with_grad,
  File "/home/dim/anaconda3/envs/libmtl/lib/python3.8/site-packages/torch/optim/_functional.py", line 92, in adam
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)
KeyboardInterrupt